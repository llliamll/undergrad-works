{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 1656 â€“ Introduction to Data Science \n",
    "\n",
    "## Instructor: Alexandros Labrinidis\n",
    "### Teaching Assistants: Evangelos Karageorgos, Xiaoting Li, Gordon Lu\n",
    "### Additional credits: Phuong Pham, Zuha Agha, Anatoli Shein\n",
    "## Recitation 7: Collaborative Filtering & Similarity Metrics\n",
    "---\n",
    "In this recitation we will be doing a fun exercise to implement collaborative filtering for recommender systems. We will also learn how the choice of similarity metric in collaborative filtering can affect its output of predicted ratings. \n",
    "\n",
    "Packages you will need for the recitation are,\n",
    "\n",
    "* pandas\n",
    "* numpy\n",
    "* scipy\n",
    "\n",
    "Recall that numpy package provides nd-arrays and operations for easily manipulating them. \n",
    "Likewise, scipy provides an addtional suite of useful mathematical functions and distributions for numpy arrays, including distance functions which we will use in this recitation to compute the measure of similarity. We will only import the distance funcions we need for today's session as shown below. Note that cityblock is just another name for Manhattan distance metric seen in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad marshal data (unknown type code)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_7404/4289627771.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspatial\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdistance\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0meuclidean\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcityblock\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcosine\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstats\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mpearsonr\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\scipy\\stats\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    382\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0m__future__\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdivision\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mprint_function\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mabsolute_import\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    383\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 384\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mstats\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    385\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mdistributions\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    386\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mmorestats\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\scipy\\stats\\stats.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    184\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mlinalg\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    185\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdistributions\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 186\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmstats_basic\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    187\u001B[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n\u001B[0;32m    188\u001B[0m                                    siegelslopes)\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap.py\u001B[0m in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap_external.py\u001B[0m in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap_external.py\u001B[0m in \u001B[0;36mget_code\u001B[1;34m(self, fullname)\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\importlib\\_bootstrap_external.py\u001B[0m in \u001B[0;36m_compile_bytecode\u001B[1;34m(data, name, bytecode_path, source_path)\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: bad marshal data (unknown type code)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean, cityblock, cosine\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Based vs Item-Based Recommendation\n",
    "There are two type of collaborative filtering method: user-based and item-based.\n",
    "\n",
    "User-based recommendation assumes that similar users give similar ratings to each item. Whereas item-based recommendation assumes that similar items receive similar ratings from each user. You can think of them as a dual of each other. \n",
    "\n",
    "In this recitation, we will walk through a toy example for user-based recommendation and you will try out item-based recommendation later in one of your tasks. \n",
    "\n",
    "## Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://data.cs1656.org/movies_example.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing rows in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two ways to access dataframes rows are shown below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting value equality test fo a Series of booleans\n",
    "df['Name'] == 'The Matrix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First way to access rows\n",
    "df[df['Name'] == 'The Matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second way\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values in data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To exlude missing values or NaNs in a dataframe, we can use the notnull() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Frank'].notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Elaine'].notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also perform logical operations on the boolean Series returned as shown below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Frank'].notnull() & df['Elaine'].notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also select subset of rows and columns where the boolean value is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notmissing = df[['Frank','Elaine']][df['Frank'].notnull() & df['Elaine'].notnull()]\n",
    "df_notmissing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Metrics & Predicted Ratings\n",
    "Different distance metrics can be used to measure the similarity. In this recitation, we will use Euclidean, Manhattan, Pearson Correlation and Cosine distance metrics to measure the similarity.\n",
    "\n",
    "### Euclidean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_weights = {}\n",
    "for user in df.columns[1:-1]:\n",
    "    df_subset = df[['Frank',user]][df['Frank'].notnull() & df[user].notnull()]\n",
    "    dist = euclidean(df_subset['Frank'], df_subset[user])\n",
    "    sim_weights[user] = 1.0 / (1.0 + dist)\n",
    "print (\"similarity weights: %s\" % sim_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the predicted rating of 'Frank' for 'The Matrix'. We can get all ratings for a movie by accessing a row of the dataframe using iloc learnt earlier. We only slice the columns of ratings we need indicated by the index [1:-1]. In this case we do not need the first column 'Name' and the last column 'Frank'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = df.iloc[0][1:-1]\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will find our predicted rating by multiplying each user weight with its corresponding rating for the movie matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rating = 0.0\n",
    "weights_sum = 0.0\n",
    "for user in df.columns[1:-1]:\n",
    "    predicted_rating += ratings[user] * sim_weights[user]\n",
    "    weights_sum += sim_weights[user]\n",
    "\n",
    "predicted_rating /= weights_sum\n",
    "print (\"predicted rating: %f\" % predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan (Cityblock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat our method of finding predicted rating using cityblock distance now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_weights = {}\n",
    "for user in df.columns[1:-1]:\n",
    "    df_subset = df[['Frank',user]][df['Frank'].notnull() & df[user].notnull()]\n",
    "    dist = cityblock(df_subset['Frank'], df_subset[user])\n",
    "    sim_weights[user] = 1.0 / (1.0 + dist)\n",
    "print (\"similarity weights: %s\" % sim_weights)\n",
    "\n",
    "predicted_rating = 0\n",
    "weights_sum = 0.0\n",
    "ratings = df.iloc[0][1:-1]\n",
    "for user in df.columns[1:-1]:\n",
    "    predicted_rating += ratings[user] * sim_weights[user]\n",
    "    weights_sum += sim_weights[user]\n",
    "\n",
    "predicted_rating /= weights_sum\n",
    "print (\"predicted rating: %f\" % predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_weights = {}\n",
    "for user in df.columns[1:-1]:\n",
    "    df_subset = df[['Frank',user]][df['Frank'].notnull() & df[user].notnull()]\n",
    "    sim_weights[user] = pearsonr(df_subset['Frank'], df_subset[user])[0]\n",
    "print (\"similarity weights: %s\" % sim_weights)\n",
    "\n",
    "predicted_rating = 0.0\n",
    "weights_sum = 0.0\n",
    "ratings = df.iloc[0][1:-1]\n",
    "for user in df.columns[1:-1]:\n",
    "    predicted_rating += ratings[user] * sim_weights[user]\n",
    "    weights_sum += sim_weights[user]\n",
    "\n",
    "predicted_rating /= weights_sum\n",
    "print (\"predicted rating: %s\" % predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why nan?\n",
    "Because anything divided by 0 is undefined. Computing it again with this modfication gives the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_rating = 0.0\n",
    "weights_sum = 0.0\n",
    "ratings = df.iloc[0][1:-1]\n",
    "for user in df.columns[1:-1]:\n",
    "    if (not np.isnan(sim_weights[user])):\n",
    "        predicted_rating += ratings[user] * sim_weights[user]\n",
    "        weights_sum += sim_weights[user]\n",
    "\n",
    "predicted_rating /= weights_sum\n",
    "print (\"predicted rating: %f\" % predicted_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "For your tasks, use the movie ratings data we collected from a previous class in movie_class_responses.csv. You will predict missing movie ratings of a student based on other students with similar tastes. The first column, 'Alias' is the name of the movie, while all other columns are user names od students. The ratings are from 1 to 5, while there are a lot of missing values (missing movie ratings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('http://data.cs1656.org/movie_class_responses.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 1: User-based Recommendation with Cosine Metric**\n",
    "\n",
    "For a specified user, calculate ALL missing movie ratings using user-based recommendation with Cosine Metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 2: Item-based Recommendation with Cosine Metric**\n",
    "\n",
    "Repeat the task above by doing an item-based recommendation instead of a user based recommendation. To calculate a missing movie rating using item-based recommendation, you are supposed to find similarity between movies instead of users. In other words, you measure the similarity of the user's missing rating movie with movies that the user has rated in the past. Then compute a weighted average using similar movie weights and their ratings to find out the predicted rating. You need to predict ALL missing movie ratings for the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Task 3: User-based Recommendation with Cosine Metric**\n",
    "\n",
    "Repeat Task 1 while computing the weighted average using just top 10 most similar users instead of all users."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "pycharm-678401ce",
   "language": "python",
   "display_name": "PyCharm (rec07-llliamll-main)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}